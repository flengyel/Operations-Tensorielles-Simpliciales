{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b2f5f9",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "#    Opérations Tensorielles Simpliciales\n",
    "#    Simplicial Operations on Matrices and Hypermatrices\n",
    "#    sagemath_compatible_tensor_ops.py\n",
    "#    \n",
    "#    Copyright (C) 2021-2025 Florian Lengyel\n",
    "#    Email: florian.lengyel at cuny edu, florian.lengyel at gmail\n",
    "#    Website: https://github.com/flengyel\n",
    "#\n",
    "#    This program is free software: you can redistribute it and/or modify\n",
    "#    it under the terms of the GNU General Public License as published by\n",
    "#    the Free Software Foundation, either version 3 of the License, or\n",
    "#    (at your option) any later version.\n",
    "#\n",
    "#    This program is distributed in the hope that it will be useful,\n",
    "#    but WITHOUT ANY WARRANTY; without even the implied warranty of\n",
    "#    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n",
    "#    GNU General Public License for more details.\n",
    "#\n",
    "#    You should have received a copy of the GNU General Public License\n",
    "#    along with this program.  If not, see <https://www.gnu.org/licenses/>.\n",
    "\n",
    "# This is the ULTIMATE, complete, and corrected version, intended to be loaded\n",
    "# into a SageMath notebook. It merges ALL functionality from the user-provided\n",
    "# files and uses Sage's symbolic engine. Nothing has been omitted.\n",
    "\n",
    "import numpy as np\n",
    "from typing import Tuple, List, Union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "736ed1",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "# Sage imports\n",
    "# This script is intended to be run within a SageMath environment.\n",
    "try:\n",
    "    from sage.all import var, latex, simplify\n",
    "    from sage.symbolic.expression import Expression\n",
    "except ImportError:\n",
    "    print(\"Warning: SageMath library not found. This script should be run in a Sage environment.\")\n",
    "    # Define dummy placeholders if not in Sage, so the file can be inspected\n",
    "    def var(s): return str(s)\n",
    "    def latex(s): return str(s)\n",
    "    def simplify(s): return s\n",
    "    class Expression: pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "46884d",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "\n",
    "class SimplicialException(Exception):\n",
    "    \"\"\"Custom exception for simplicial operations.\"\"\"\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d88ca4",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "class SymbolicTensor:\n",
    "    \"\"\"\n",
    "    A tensor with symbolic entries, compatible with the SageMath ecosystem.\n",
    "    \"\"\"\n",
    "    def __init__(self, shape: Tuple[int,...], tensor_data=None, init_type: str = 'range'):\n",
    "        self.shape = shape\n",
    "        if tensor_data is not None:\n",
    "            self.tensor = np.array(tensor_data, dtype=object)\n",
    "            if self.tensor.shape != self.shape:\n",
    "                raise ValueError(f\"Provided data shape {self.tensor.shape} does not match specified shape {self.shape}\")\n",
    "        else:\n",
    "            self.tensor = np.empty(shape, dtype=object)\n",
    "            for idx in np.ndindex(shape):\n",
    "                idx_str = '_'.join(map(str, idx))\n",
    "                if init_type == 'range':\n",
    "                    self.tensor[idx] = var(f'x_{idx_str}')\n",
    "                elif init_type == 'zeros':\n",
    "                    self.tensor[idx] = 0\n",
    "                elif init_type == 'ones':\n",
    "                    self.tensor[idx] = 1\n",
    "                else:\n",
    "                    raise ValueError(f\"Unsupported init_type: {init_type}\")\n",
    "\n",
    "    @staticmethod\n",
    "    def from_tensor(tensor_array):\n",
    "        return SymbolicTensor(tensor_array.shape, tensor_data=tensor_array)\n",
    "\n",
    "    def __str__(self): return str(self.tensor)\n",
    "    def __repr__(self): return f\"SymbolicTensor(shape={self.shape})\"\n",
    "    def __sub__(self, other):\n",
    "        if not isinstance(other, SymbolicTensor) or self.shape != other.shape: return NotImplemented\n",
    "        return SymbolicTensor(self.shape, tensor_data=(self.tensor - other.tensor))\n",
    "    def __add__(self, other):\n",
    "        if not isinstance(other, SymbolicTensor) or self.shape != other.shape: return NotImplemented\n",
    "        return SymbolicTensor(self.shape, tensor_data=(self.tensor + other.tensor))\n",
    "\n",
    "    def dimen(self) -> int:\n",
    "        if not self.shape or any(s == 0 for s in self.shape): return -1\n",
    "        return min(self.shape) - 1\n",
    "\n",
    "    def order(self) -> int:\n",
    "        return len(self.shape)\n",
    "\n",
    "    def _dims(self):\n",
    "        return tuple([np.arange(dim_size) for dim_size in self.shape])\n",
    "\n",
    "    def face(self, i: int) -> \"SymbolicTensor\":\n",
    "        num_faces = min(self.shape) if self.shape else 0\n",
    "        if not (0 <= i < num_faces):\n",
    "            raise IndexError(f\"Face index {i} out of bounds for shape {self.shape}.\")\n",
    "        axes = self._dims()\n",
    "        indices_for_grid = [np.delete(ax, i) for ax in axes]\n",
    "        grid = np.ix_(*indices_for_grid)\n",
    "        return SymbolicTensor.from_tensor(self.tensor[grid])\n",
    "\n",
    "    def degen(self, k: int) -> \"SymbolicTensor\":\n",
    "        n = self.dimen()\n",
    "        if not (0 <= k <= n):\n",
    "            raise IndexError(f\"Degeneracy index {k} out of bounds for dimension {n}.\")\n",
    "        result_data = self.tensor\n",
    "        for axis in range(self.order()):\n",
    "            slice_obj = [slice(None)] * self.order()\n",
    "            slice_obj[axis] = k\n",
    "            slice_to_duplicate = result_data[tuple(slice_obj)]\n",
    "            result_data = np.insert(result_data, k, slice_to_duplicate, axis=axis)\n",
    "        return SymbolicTensor.from_tensor(result_data)\n",
    "\n",
    "    def bdry(self) -> \"SymbolicTensor\":\n",
    "        n = self.dimen()\n",
    "        if n < 0: raise SimplicialException(\"Boundary of tensor with dim < 0 is undefined.\")\n",
    "        result_shape = tuple(s - 1 for s in self.shape)\n",
    "        result_tensor_data = np.zeros(result_shape, dtype=object)\n",
    "        for i in range(n + 1):\n",
    "            face_i = self.face(i)\n",
    "            if (i % 2) == 0: result_tensor_data += face_i.tensor\n",
    "            else: result_tensor_data -= face_i.tensor\n",
    "        return SymbolicTensor.from_tensor(result_tensor_data)\n",
    "\n",
    "    def horn(self, k: int) -> list:\n",
    "        n = self.dimen()\n",
    "        if not (0 <= k <= n): raise ValueError(f\"Horn index {k} must be in [0, {n}]\")\n",
    "        faces = []\n",
    "        for i in range(n + 1):\n",
    "            if i == k:\n",
    "                faces.append(SymbolicTensor(tuple(s - 1 for s in self.shape), init_type='zeros'))\n",
    "            else:\n",
    "                faces.append(self.face(i))\n",
    "        return faces\n",
    "\n",
    "    def filler(self, horn_list: list, k: int) -> \"SymbolicTensor\":\n",
    "        g = horn_list[k].degen(0)\n",
    "        for r in range(k):\n",
    "            face_gr = g.face(r)\n",
    "            diff_tensor = np.zeros(face_gr.shape, dtype=object)\n",
    "            for idx in np.ndindex(face_gr.shape):\n",
    "                diff_tensor[idx] = face_gr.tensor[idx] - horn_list[r].tensor[idx]\n",
    "            degen_diff = SymbolicTensor(face_gr.shape, tensor_data=diff_tensor).degen(r)\n",
    "            g.tensor = g.tensor - degen_diff.tensor\n",
    "        t = len(horn_list) - 1\n",
    "        while t > k:\n",
    "            face_gt = g.face(t)\n",
    "            diff_tensor = np.zeros(face_gt.shape, dtype=object)\n",
    "            for idx in np.ndindex(face_gt.shape):\n",
    "                diff_tensor[idx] = horn_list[t].tensor[idx] - face_gt.tensor[idx]\n",
    "            degen_diff = SymbolicTensor(face_gt.shape, tensor_data=diff_tensor).degen(t - 1)\n",
    "            g.tensor = g.tensor + degen_diff.tensor\n",
    "            t -= 1\n",
    "        return g\n",
    "    \n",
    "    def is_degen(self) -> bool:\n",
    "        n = self.dimen()\n",
    "        for i in range(n + 1):\n",
    "            try:\n",
    "                if np.all([(simplify(a - b) == 0) for a, b in zip(self.tensor.flatten(), self.face(i).degen(i).tensor.flatten())]):\n",
    "                    return True\n",
    "            except IndexError: continue\n",
    "        return False\n",
    "\n",
    "    def n_hypergroupoid_comparison(self, outer_horns=False, verbose=False, allow_degen=False):\n",
    "        boundary = self.bdry()\n",
    "        if not allow_degen and boundary.is_degen():\n",
    "            if verbose: print(\"Boundary is degenerate.\")\n",
    "            raise SimplicialException(\"Degenerate boundary.\")\n",
    "        dim = self.dimen()\n",
    "        horn_range = range(0 if outer_horns else 1, dim + 1 if outer_horns else dim)\n",
    "        filler_i = None # To ensure it's in scope\n",
    "        for i in horn_range:\n",
    "            if verbose: print(f\"Testing horn {i}...\")\n",
    "            horn_i = self.horn(i)\n",
    "            filler_i = self.filler(horn_i, i)\n",
    "            horn_i_prime = filler_i.horn(i)\n",
    "            for j in range(len(horn_i)):\n",
    "                if j == i: continue\n",
    "                original = horn_i[j]\n",
    "                reproduced = horn_i_prime[j]\n",
    "                if np.any([(simplify(o-r) != 0) for o,r in zip(original.tensor.flatten(), reproduced.tensor.flatten())]):\n",
    "                    raise SimplicialException(f\"Original horn and filler horn disagree at face {j}.\")\n",
    "        \n",
    "        # Check if original tensor T is recovered\n",
    "        if filler_i is None: # handle case where loop does not run\n",
    "             return True\n",
    "\n",
    "        diff = self - filler_i\n",
    "        if np.any(diff.simplify().tensor != 0):\n",
    "            if verbose: print(\"Multiple fillers exist.\")\n",
    "            return False\n",
    "        if verbose: print(\"Unique filler.\")\n",
    "        return True\n",
    "\n",
    "    def simplify(self):\n",
    "        for idx in np.ndindex(self.shape): self.tensor[idx] = simplify(self.tensor[idx])\n",
    "        return self\n",
    "    \n",
    "    def subs(self, substitutions: dict):\n",
    "        for idx in np.ndindex(self.shape): self.tensor[idx] = self.tensor[idx].subs(substitutions)\n",
    "        return self\n",
    "\n",
    "    def to_latex(self):\n",
    "        if len(self.shape) != 2: return \"LaTeX representation only available for 2D tensors.\"\n",
    "        rows, cols = self.shape\n",
    "        latex_str = \"\\\\begin{bmatrix}\\n\"\n",
    "        for i in range(rows):\n",
    "            latex_str += \" & \".join([latex(self.tensor[i, j]) for j in range(cols)])\n",
    "            if i < rows - 1: latex_str += \" \\\\\\\\\\n\"\n",
    "        latex_str += \"\\n\\\\end{bmatrix}\"\n",
    "        return latex_str\n",
    "\n",
    "    def decompose_degen(self) -> Tuple[\"SymbolicTensor\", List[Tuple[\"SymbolicTensor\", int]]]:\n",
    "        operations = []\n",
    "        def helper(tensor: \"SymbolicTensor\", ops: List) -> \"SymbolicTensor\":\n",
    "            d = tensor.dimen()\n",
    "            for i in range(d + 1):\n",
    "                try:\n",
    "                    face_i = tensor.face(i)\n",
    "                    degen_i = face_i.degen(i)\n",
    "                    if degen_i.shape == tensor.shape and np.all([(simplify(a - b) == 0) for a, b in zip(tensor.tensor.flatten(), degen_i.tensor.flatten())]):\n",
    "                        ops.append((face_i, i))\n",
    "                        return helper(face_i, ops)\n",
    "                except IndexError: continue\n",
    "            return tensor\n",
    "        base = helper(self, operations)\n",
    "        return base, operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ef236f",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "# --- Standalone helper functions ---\n",
    "\n",
    "def correction_rank(original: SymbolicTensor, filler: SymbolicTensor) -> int:\n",
    "    if original.shape != filler.shape:\n",
    "        raise ValueError(\"Tensors must have the same shape to compare.\")\n",
    "    differences = set()\n",
    "    for idx in np.ndindex(original.shape):\n",
    "        diff = simplify(original.tensor[idx] - filler.tensor[idx])\n",
    "        if diff != 0:\n",
    "            differences.add(str(diff))\n",
    "    return len(differences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "dd8ece",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "def n_hypergroupoid_conjecture(shape: Tuple[int, ...], verbose=False) -> bool:\n",
    "    if not shape or any(s == 0 for s in shape): return True \n",
    "    k = len(shape)\n",
    "    N = min(shape) - 1\n",
    "    if verbose:\n",
    "        print(f\"Conjecture check for shape {shape}: k={k}, N={N}. Prediction (unique?): {k < N}\")\n",
    "    return k < N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4193d3",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "def test_symbolic_n_hypergroupoid(shape: Tuple[int,...], verbose=True):\n",
    "    sym_tensor = SymbolicTensor(shape)\n",
    "    conjecture = n_hypergroupoid_conjecture(shape, verbose=verbose)\n",
    "    try:\n",
    "        comparison = sym_tensor.n_hypergroupoid_comparison(outer_horns=True, verbose=verbose)\n",
    "        if verbose:\n",
    "            print(f\"Conjecture predicts unique fillers: {conjecture}\")\n",
    "            print(f\"Filler uniqueness observed: {comparison}\")\n",
    "            if conjecture == comparison: print(\"✔️  The n-hypergroupoid conjecture is confirmed for this shape.\")\n",
    "            else: print(\"❌  Observation does not match conjecture prediction.\")\n",
    "        return conjecture, comparison, sym_tensor\n",
    "    except SimplicialException as e:\n",
    "        if \"Degenerate boundary\" in str(e):\n",
    "            if verbose: print(\"Skipping comparison due to degenerate boundary.\")\n",
    "            return conjecture, None, sym_tensor\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "033806",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "def check_symbolic_corrections(t: SymbolicTensor, t_prime: SymbolicTensor, horn_faces: list, k: int) -> bool:\n",
    "    n = t.dimen()\n",
    "    print(f\"Checking horn({n},{k}) indices missing from symbolic tensor with shape {t.shape}.\")\n",
    "    all_symbols = set(str(s) for s in t.tensor.flatten() if s != 0)\n",
    "    face_symbol_union = set()\n",
    "    for face_idx, face in enumerate(horn_faces):\n",
    "        if face_idx == k: continue\n",
    "        for expr in face.tensor.flatten():\n",
    "            if simplify(expr) != 0: face_symbol_union.add(str(expr))\n",
    "    missing_symbols = all_symbols - face_symbol_union\n",
    "    changed_symbols = set()\n",
    "    diff = t - t_prime\n",
    "    for idx in np.ndindex(t.shape):\n",
    "        if simplify(diff.tensor[idx]) != 0:\n",
    "            original_symbol = t.tensor[idx]\n",
    "            if original_symbol != 0: changed_symbols.add(str(original_symbol))\n",
    "            else: changed_symbols.add(str(t_prime.tensor[idx]))\n",
    "    if changed_symbols == missing_symbols:\n",
    "        print(f\"Success: The filler differed from the original at {len(missing_symbols)} indices, matching the set of missing symbols.\")\n",
    "        return True\n",
    "    else:\n",
    "        print(\"Mismatch in correction terms vs. missing symbols.\")\n",
    "        extra = changed_symbols - missing_symbols\n",
    "        missed = missing_symbols - changed_symbols\n",
    "        if extra: print(\"Symbols changed that were not missing:\", extra)\n",
    "        if missed: print(\"Symbols missing but unchanged:\", missed)\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "24b0d4",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Running Full Test and Validation Suite from Original Files ---\n",
      "\n",
      "--- Test from original sagemath_compatible_tensor_ops.py ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (3, 3), Conjecture predicts unique: False, Observed unique: False\n",
      "\n",
      "Comparison of original and filler tensors for shape (3,3):\n",
      "Checking horn(2,1) indices missing from symbolic tensor with shape (3, 3).\n",
      "Success: The filler differed from the original at 2 indices, matching the set of missing symbols.\n",
      "Check result: True\n",
      "\n",
      "--- Test loop from original symbolic_tensor_ops.py ---\n",
      "\n",
      "Building Horn(3,0) of generic tensor of shape: (4, 4, 4)\n",
      "Checking horn(3,0) indices missing from symbolic tensor with shape (4, 4, 4).\n",
      "Success: The filler differed from the original at 6 indices, matching the set of missing symbols.\n",
      "Result for shape (4, 4, 4), horn 0: True\n",
      "\n",
      "Building Horn(3,1) of generic tensor of shape: (4, 4, 4)\n",
      "Checking horn(3,1) indices missing from symbolic tensor with shape (4, 4, 4).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success: The filler differed from the original at 6 indices, matching the set of missing symbols.\n",
      "Result for shape (4, 4, 4), horn 1: True\n",
      "\n",
      "Building Horn(3,2) of generic tensor of shape: (4, 4, 4)\n",
      "Checking horn(3,2) indices missing from symbolic tensor with shape (4, 4, 4).\n",
      "Success: The filler differed from the original at 6 indices, matching the set of missing symbols.\n",
      "Result for shape (4, 4, 4), horn 2: True\n",
      "\n",
      "Building Horn(3,3) of generic tensor of shape: (4, 4, 4)\n",
      "Checking horn(3,3) indices missing from symbolic tensor with shape (4, 4, 4).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success: The filler differed from the original at 6 indices, matching the set of missing symbols.\n",
      "Result for shape (4, 4, 4), horn 3: True\n",
      "\n",
      "Building Horn(4,0) of generic tensor of shape: (5, 5, 5, 5)\n",
      "Checking horn(4,0) indices missing from symbolic tensor with shape (5, 5, 5, 5).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success: The filler differed from the original at 24 indices, matching the set of missing symbols.\n",
      "Result for shape (5, 5, 5, 5), horn 0: True\n",
      "\n",
      "Building Horn(4,1) of generic tensor of shape: (5, 5, 5, 5)\n",
      "Checking horn(4,1) indices missing from symbolic tensor with shape (5, 5, 5, 5).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success: The filler differed from the original at 24 indices, matching the set of missing symbols.\n",
      "Result for shape (5, 5, 5, 5), horn 1: True\n",
      "\n",
      "Building Horn(4,2) of generic tensor of shape: (5, 5, 5, 5)\n",
      "Checking horn(4,2) indices missing from symbolic tensor with shape (5, 5, 5, 5).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success: The filler differed from the original at 24 indices, matching the set of missing symbols.\n",
      "Result for shape (5, 5, 5, 5), horn 2: True\n",
      "\n",
      "Building Horn(4,3) of generic tensor of shape: (5, 5, 5, 5)\n",
      "Checking horn(4,3) indices missing from symbolic tensor with shape (5, 5, 5, 5).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success: The filler differed from the original at 24 indices, matching the set of missing symbols.\n",
      "Result for shape (5, 5, 5, 5), horn 3: True\n",
      "\n",
      "Building Horn(4,4) of generic tensor of shape: (5, 5, 5, 5)\n",
      "Checking horn(4,4) indices missing from symbolic tensor with shape (5, 5, 5, 5).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success: The filler differed from the original at 24 indices, matching the set of missing symbols.\n",
      "Result for shape (5, 5, 5, 5), horn 4: True\n",
      "\n",
      "Building Horn(5,0) of generic tensor of shape: (6, 6, 6, 6, 6)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking horn(5,0) indices missing from symbolic tensor with shape (6, 6, 6, 6, 6).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success: The filler differed from the original at 120 indices, matching the set of missing symbols.\n",
      "Result for shape (6, 6, 6, 6, 6), horn 0: True\n",
      "\n",
      "Building Horn(5,1) of generic tensor of shape: (6, 6, 6, 6, 6)\n",
      "Checking horn(5,1) indices missing from symbolic tensor with shape (6, 6, 6, 6, 6).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success: The filler differed from the original at 120 indices, matching the set of missing symbols.\n",
      "Result for shape (6, 6, 6, 6, 6), horn 1: True\n",
      "\n",
      "Building Horn(5,2) of generic tensor of shape: (6, 6, 6, 6, 6)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking horn(5,2) indices missing from symbolic tensor with shape (6, 6, 6, 6, 6).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success: The filler differed from the original at 120 indices, matching the set of missing symbols.\n",
      "Result for shape (6, 6, 6, 6, 6), horn 2: True\n",
      "\n",
      "Building Horn(5,3) of generic tensor of shape: (6, 6, 6, 6, 6)\n",
      "Checking horn(5,3) indices missing from symbolic tensor with shape (6, 6, 6, 6, 6).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success: The filler differed from the original at 120 indices, matching the set of missing symbols.\n",
      "Result for shape (6, 6, 6, 6, 6), horn 3: True\n",
      "\n",
      "Building Horn(5,4) of generic tensor of shape: (6, 6, 6, 6, 6)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking horn(5,4) indices missing from symbolic tensor with shape (6, 6, 6, 6, 6).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success: The filler differed from the original at 120 indices, matching the set of missing symbols.\n",
      "Result for shape (6, 6, 6, 6, 6), horn 4: True\n",
      "\n",
      "Building Horn(5,5) of generic tensor of shape: (6, 6, 6, 6, 6)\n",
      "Checking horn(5,5) indices missing from symbolic tensor with shape (6, 6, 6, 6, 6).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success: The filler differed from the original at 120 indices, matching the set of missing symbols.\n",
      "Result for shape (6, 6, 6, 6, 6), horn 5: True\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    # This block is intended to be run in a SageMath environment.\n",
    "    # It can be copy-pasted into a Sage notebook cell after loading this file.\n",
    "    print(\"--- Running Full Test and Validation Suite from Original Files ---\")\n",
    "    try:\n",
    "        _ = var # Check if we are in a Sage environment\n",
    "    except NameError:\n",
    "        print(\"\\nERROR: This script must be run in a SageMath environment.\")\n",
    "    else:\n",
    "        # Example from original sagemath_compatible_tensor_ops.py\n",
    "        print(\"\\n--- Test from original sagemath_compatible_tensor_ops.py ---\")\n",
    "        shape = (3, 3)\n",
    "        conjecture, comparison, sym_tensor = test_symbolic_n_hypergroupoid(shape, verbose=False)\n",
    "        print(f\"Shape: {shape}, Conjecture predicts unique: {conjecture}, Observed unique: {comparison}\")\n",
    "        horn_1 = sym_tensor.horn(1)\n",
    "        filler_1 = sym_tensor.filler(horn_1, 1)\n",
    "        print(\"\\nComparison of original and filler tensors for shape (3,3):\")\n",
    "        result = check_symbolic_corrections(sym_tensor, filler_1, horn_1, 1)\n",
    "        print(f\"Check result: {result}\")\n",
    "\n",
    "        # Test loop from original symbolic_tensor_ops.py\n",
    "        print(\"\\n--- Test loop from original symbolic_tensor_ops.py ---\")\n",
    "        def build_shape(n: int) -> Tuple[int,...]:\n",
    "            return tuple(n+1 for _ in range(n))\n",
    "        for k_order in range(3, 6):\n",
    "            for j_horn in range(k_order + 1):\n",
    "                shape = build_shape(k_order)\n",
    "                print(f\"\\nBuilding Horn({k_order},{j_horn}) of generic tensor of shape: {shape}\")\n",
    "                try:\n",
    "                    sym_tensor = SymbolicTensor(shape=shape)\n",
    "                    horn = sym_tensor.horn(j_horn)\n",
    "                    filler = sym_tensor.filler(horn, j_horn)\n",
    "                    result = check_symbolic_corrections(sym_tensor, filler, horn, j_horn)\n",
    "                    print(f\"Result for shape {shape}, horn {j_horn}: {result}\")\n",
    "                except Exception as e:\n",
    "                    print(f\"An error occurred for shape {shape}, horn {j_horn}: {e}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "id": "dfd05b",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "argv": [
    "sage-10.6",
    "--python",
    "-m",
    "sage.repl.ipython_kernel",
    "--matplotlib=inline",
    "-f",
    "{connection_file}"
   ],
   "display_name": "SageMath 10.6",
   "env": {
   },
   "language": "sagemath",
   "metadata": {
    "cocalc": {
     "description": "Open-source mathematical software system",
     "priority": 10,
     "url": "https://www.sagemath.org/"
    }
   },
   "name": "sage-10.6",
   "resource_dir": "/ext/jupyter/kernels/sage-10.6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}