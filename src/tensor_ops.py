#    Opérations Tensorielles Simpliciales
#    Simplicial Operations on Matrices and Hypermatrices
#    tensor_ops.py
#    
#    Copyright (C) 2021-2025 Florian Lengyel
#    Email: florian.lengyel at cuny edu, florian.lengyel at gmail
#    Website: https://github.com/flengyel
#
#    This program is free software: you can redistribute it and/or modify
#    it under the terms of the GNU General Public License as published by
#    the Free Software Foundation, either version 3 of the License, or
#    (at your option) any later version.
#
#    This program is distributed in the hope that it will be useful,
#    but WITHOUT ANY WARRANTY; without even the implied warranty of
#    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
#    GNU General Public License for more details.
#
#    You should have received a copy of the GNU General Public License
#    along with this program.  If not, see <https://www.gnu.org/licenses/>.

import numpy as np
from typing import Tuple, List, Union, Any
import logging
import random

# DO NOT SET UP LOGGING HERE
# logging.basicConfig(level=logging.WARNING)

___SEED___ = 123  # Set the seed value for reproducibility
random.seed(___SEED___)  # Set the seed value for random library 
np.random.seed(___SEED___)  # Set the seed value for np.random library
rng = np.random.default_rng(___SEED___)  # Create a random number generator with the seed

## Tensor construction functions

def random_tensor(shape: Tuple[int, ...], low: int = 1, high: int = 10, seed: int = ___SEED___) -> np.ndarray:
    if seed != ___SEED___:
        rng_to_use = np.random.default_rng(seed)
    else:
        rng_to_use = rng  # Use the global rng defined with ___SEED___
    return rng_to_use.integers(low=low, high=high, size=shape, dtype=np.int16)

def random_real_tensor(shape: Tuple[int, ...], mean: float = 0.0, std: float = 1.0, seed: int = ___SEED___) -> np.ndarray:
    if seed != ___SEED___:
        rng_to_use = np.random.default_rng(seed)
    else:
        rng_to_use = rng  # Use the global rng defined with ___SEED___
    return rng_to_use.normal(loc=mean, scale=std, size=shape)


# create a tensor with a given shape and values from 0 to n-1,
# where n is the product of the shape dimensions
def range_tensor(shape: Tuple[int, ...]) -> np.ndarray:
    return np.arange(np.prod(shape)).reshape(shape)

def get_index(j: int, shape: Tuple[int, ...]) -> Tuple[int, ...]:
    """
    Returns the multi-dimensional index of the element in a tensor of specified shape that corresponds to the flat index j.
    
    :param j: int, flat index within the array produced by np.arange(prod(shape))
    :param shape: tuple of ints, shape of the tensor
    :return: tuple of ints, multi-dimensional index in the tensor
    """
    if j < 0 or j >= np.prod(shape):
        raise ValueError("Index out of bounds")
    return tuple(int(idx) for idx in np.unravel_index(j, shape))


def dimen(t: np.ndarray) -> int:
    """
    Calculates the dimension of a hypermatrix t, defined as min(t.shape)-1.
    This represents the dimension of the hypermatrix t in the simplicial hypermatrix R-module
    generated by t, where R is a ring and t has entries in R.

    Parameters:
        t (np.ndarray): The hypermatrix for which to calculate the simplex dimension.

    Returns:
        int: The simplex dimension of the hypermatrix.
    """
    return min(t.shape) - 1

def order(t: np.ndarray) -> int:
    """
    Calculates the order of a hypermatrix t, defined as the number of dimensions of t.

    Parameters:
        t (np.ndarray): The hypermatrix for which to calculate the order.

    Returns:
        int: The order of the hypermatrix.
    """
    return len(t.shape)

# dimensions d'une matrice sous forme d'un tuple de listes d'indices de lignes et de colonnes
# par exemple, _dims(M) = ([0,1,2,3], [0,1,2,3,4,5,6,7,8])
# Cette précomputation est utilisée pour éviter de recalculer la même liste d'indices
# dans les calculs de frontière

def _dims(m: np.ndarray) -> Tuple[List[np.ndarray], ...]:
    return tuple([np.arange(dim_size) for dim_size in m.shape])

# Généralisation de l'opération face aux tenseurs
def _face(m: np.ndarray, axes: Tuple[List[np.ndarray], ...], i: int) -> np.ndarray:
    rows, cols = axes[0], axes[1]
    indices = [np.delete(axis, i) if len(axis) > i else axis for axis in axes]
    grid = np.ix_(*indices)
    return m[grid]

# i-ème face d'une matrice
def face(m: np.ndarray, i: int) -> np.ndarray:
    axes = _dims(m)
    return _face(m, axes, i)

# i-ème face horizontale d'une matrice, avec des indices dimensionnels donnés par les lignes et les colonnes
# def _hface(m: np.ndarray, rows: np.ndarray, cols: np.ndarray, i: int) -> np.ndarray:
def _hface(m: np.ndarray, axes: Tuple[List[np.ndarray], ...], i: int) -> np.ndarray:
    rows, cols = axes[0], axes[1]
    grid = np.ix_(np.delete(rows, i), cols)
    return m[grid]

# i-ème face horizontale d'une matrice
def hface(m: np.ndarray, i: int) -> np.ndarray:
    return _hface(m, _dims(m), i)

# i-ème face verticale d'une matrice, avec des indices dimensionnels donnés par les lignes et les colonnes
def _vface(m: np.ndarray, axes: Tuple[List[np.ndarray], ...], i: int) -> np.ndarray:
    rows, cols = axes[0], axes[1]
    grid = np.ix_(rows, np.delete(cols, i))
    return m[grid]

#  i-ème face verticale d'une matrice
def vface(m: np.ndarray, i: int) -> np.ndarray:
    return _vface(m, _dims(m), i)

#  j-ème dégénérescence verticale d'une matrice
def vdegen(z: np.ndarray, j: int) -> np.ndarray:
    return np.insert(z, j, z[:, j], axis=1)

#  j-ème dégénérescence horizontale d'une matrice
def hdegen(z: np.ndarray, j: int) -> np.ndarray:
    return np.insert(z, j, z[j, :], axis=0)

# j-ème dégénérescence d'une matrice
def degen_matrix(z: np.ndarray, j: int) -> np.ndarray:
    z_with_row = np.insert(z, j, z[j, :], axis=0)
    z_with_row_and_col = np.insert(z_with_row, j, z_with_row[:, j], axis=1)
    return z_with_row_and_col

# k-ème dégénérescence d'un tenseur
def degen(z: np.ndarray, k: int) -> np.ndarray:
    # Parcourez chaque dimension et dupliquez la k-ème hypercolonne
    for axis in range(z.ndim):
        # Each element of slices can be either a slice or an int, 
        # which NumPy indexing with tuple(slices) accepts
        # slice(None) means "take all elements along this axis"
        slices: list[Union[int, slice]] = [slice(None)] * z.ndim
        slices[axis] = k  # duplicate the k-th index 
        z = np.insert(z, k, z[tuple(slices)], axis=axis)
    return z

def is_degen(a: np.ndarray) -> bool:
    d = dimen(a) 
    for i in np.arange(d): # faces have simplicial dimension d
        if np.array_equal(a, degen(face(a, int(i)), int(i))):
            return True
    return False

def is_generator_numeric(a: np.ndarray) -> bool:
    """
    Symbolic test for generator:
    - Let n = min(a.shape).
    - Zero tensor (all entries 0) cannot be a generator in tensor local coefficient homology.
    - Otherwise, f n <= 1 (0-simplices), non-degenerate.
    - If n == 2, degenerate if constant (all entries equal).
    - If n > 2, degenerate if a == num_degen(face(a,i), i) for some i.
    """
    #print(f"[DEBUG] is_generator_numeric: tensor shape={a.shape}")
    if np.all(a == 0):
        #print("[DEBUG] is_generator_numeric: zero tensor cannot be a generator")
        return False
    n = min(a.shape)
    if n <= 1:
        #print("[DEBUG] is_generator_numeric: nonzero, dimension 0 is a generator")
        return True
    flat = a.flatten()
    if n == 2: # dimension 1 
        is_constant = bool(np.all(flat == flat[0]))
        #print(f"[DEBUG] is_generator_numeric: n==2, constant? {is_constant}")
        return not is_constant
    
    for i in range(n):
        try:
            B = face(a, i)
            C = degen(B, i)
        except IndexError:
            continue
        if np.array_equal(a, C):
            #print(f"[DEBUG] is_generator_numeric: degeneracy via face+degen at i={i}")
            return False
    #print("[DEBUG] is_generator_numeric: no degeneracy found")
    return True


def find_degen(a: np.ndarray) -> Union[Tuple[np.ndarray, int], None]:   
    d = dimen(a) 
    for i in np.arange(d): # faces have simplicial dimension d
        if np.array_equal(a, degen(face(a, int(i)), int(i))):
            return face(a, int(i)), int(i)
    return None    

# Decompose a degenerate matrix into a non-degenerate base matrix and a sequence of degeneracy operations
# Example usage
# A = np.array([[...], [...]])  # Replace with an actual hypermatrix
# non_degenerate_base, ops = decomposeDegeneracy(A)
# print("Non-degenerate base matrix:", non_degenerate_base)
# print("Sequence of degeneracy operations:", ops)

def decompose_degen(a: np.ndarray) -> Tuple[np.ndarray, list]:
    operations = []

    def helper(b: np.ndarray, ops: list) -> np.ndarray:
        nonlocal operations
        degeneracy_info = find_degen(b)
        
        # Base case: If B is non-degenerate or no degeneracy found, set the operations
        if degeneracy_info is None:
            operations = ops
            return b
        
        # Recursive case
        f, i = degeneracy_info
        return helper(f, ops + [(f, i)])

    # Start the decomposition
    non_degenerate_base = helper(a, [])
    return non_degenerate_base, operations

# Frontière d'un tenseur
def bdry(m: np.ndarray) -> np.ndarray:
    d = np.min(m.shape)
    axes = _dims(m)
    #  soustraire 1 de chaque dimension
    a = np.zeros(np.subtract(m.shape, np.array([1])), dtype=m.dtype)
    for i in range(d):
       if i % 2 == 0:
           a = np.add(a, _face(m, axes, i))
       else:
           a = np.subtract(a, _face(m, axes, i))
    return a

#  Frontière horizontale d'une matrice
def hbdry(m: np.ndarray) -> np.ndarray:
    d = m.shape[0]
    axes = _dims(m)
    # soustraire 1 de la dimension zéro
    a = np.zeros(np.subtract(m.shape,np.array([1,0])))
    for i in range(d):
        if i % 2 == 0:
            a = np.add(a, _hface(m, axes, i))
        else:
            a = np.subtract(a, _hface(m, axes, i))
    return a

#  Frontière verticale d'une matrice
def vbdry(m: np.ndarray) -> np.ndarray:
    d = m.shape[1]
    axes = _dims(m)
    # soustraire 1 de la première dimension
    a = np.zeros(np.subtract(m.shape,np.array([0,1])))
    for i in range(d):
        if i % 2 == 0:
            a = np.add(a, _vface(m, axes, i))
        else:
            a = np.subtract(a, _vface(m, axes, i))  
    return a

# cobord d'une matrice. Cela donnera toujours une cohomologie nulle
def cobdry(m: np.ndarray) -> np.ndarray:
    d = np.min(m.shape)
    # Ajoutez 1 à chaque dimension
    a = np.zeros(np.add(m.shape,np.array([1])))
    for i in range(d):
       if i % 2 == 0:
           a = np.add(a, degen(m, i))
       else:
           a = np.subtract(a, degen(m, i))
    return a

# Fonction de cornet, donnée une matrice M et un indice k, 0 <= k <= dimen(M)+1 = min(M.shape).
# Ceci retourne la liste des faces diagonales de M en ordre à l'exception de la k-ème.
# La k-ème matrice est la matrice zéro de dimension (M.shape[0]-1)x(M.shape[1]-1)
def horn(m: np.ndarray, k: int) -> np.ndarray:
    d = dimen(m)+1 
    if k < 0 or k > d:
        raise ValueError(k, "must be nonnegative and less than or equal to dim+1", d)
    return np.array([face(m,i) if i != k else np.zeros(np.subtract(m.shape, np.array([1]))) for i in range(d)])

# check the Kan condition
def kan_condition(w: np.ndarray, k: int) -> bool:
    d = len(w)
    for j in range(d):
        for i in range(j): # i < j
            if i < j and i != k and j != k:
                if not np.array_equal(face(w[j],i), face(w[i],j-1)):
                   return False
    return True

# Moore's algorithm for producing a filler of a horn
# Based on Lemma 8.2.6 in Weibel 2003, pp 262.
# The function filler() computes a hypermatrix, 
# given a horn H which omits the k-th face
# Here a k-horn has a zero matrix at the k-th position
def filler(horn: np.ndarray, k: int) -> np.ndarray:
    g = degen(horn[k],0) # zero matrix at k-th position in Horn
    for r in range(k):
        u = np.subtract(face(g, r), horn[r])
        g = np.subtract(g, degen(u, r))
    # begin the downward induction
    t = len(horn)-1
    while t > k:
        z = degen(np.subtract(horn[t], face(g,t)), t-1)
        g = np.add(g, z)
        t -= 1
    return g

def standard_basis_matrix(m: int, n: int, i: int, j: int) -> np.ndarray:
    # Create a zero matrix of dimensions (m, n)
    s = np.zeros((m, n))
    # Set the element at (i, j) to 1
    s[i, j] = 1
    return s


# Definition: the order of a tensor t is the number of dimensions of t.

# The n-hypergroupoid conjecture. Let t be a (non-degenerate?) hypermatrix
# with non-degenerate boundary (necessary). Then the (inner) horns of t are unique 
# if and only if the order of t is less than its dimension: order(t) < dimen(t).
def n_hypergroupoid_conjecture(shape: Tuple[int, ...], verbose: bool = False) -> bool:
    _order = len(shape)
    _dimension = min(shape)-1 # simplicial dimension
    conjecture = _order < _dimension
    if verbose:
        print(f"shape:{shape} order:{_order} {'<' if conjecture else '>='} dim:{_dimension}")
    return conjecture

# custom exception for simplicial tensors
class SimplicialException(Exception):
    pass

# Conjecture. Supppse that bdry(a) is non-degenerate. 
# Then every inner horn of a has a unique filler if and only if deg(a) < dimen(a)
# We added the parameter outer_horns to allow for the comparison of outer horns as well.
def n_hypergroupoid_comparison(a: np.ndarray, outer_horns: bool = False, verbose: bool = False, allow_degen=False) -> bool:
    if not allow_degen and is_degen(bdry(a)):
        raise SimplicialException("Degenerate boundary.")
    dim = dimen(a)
    # if outer_horns is True, then we need to check the outer horns as well
    for i in range(0 if outer_horns else 1, dim+1 if outer_horns else dim):
        h = horn(a, i)
        b = filler(h, i)
        hprime = horn(b, i)
        if not np.array_equal(h,hprime):
            raise SimplicialException("Original horn and filler horn disagree!")
        if not np.array_equal(a, b):
            if verbose:
                print(f"There exist at least two fillers for omitted face {i}.")
            return False
    if verbose:
        print("Unique filler.")
    return True

# max norm of a hypermatrix
def max_norm(hyp : np.ndarray) -> Union[int, float]:
    return np.max(np.abs(hyp))

# Normed boundary
def bdry_n(h: np.ndarray) -> np.ndarray:
    if np.any(h):  # Check if h is non-zero
        norm = max_norm(h)
        if norm != 0:
            return bdry(h) / norm
        else:
            # Log a warning if h is non-zero but max_norm is effectively zero
            logging.warning("Non-zero array has an effective max norm of zero. Returning bdry(h) instead.")
            return bdry(h)  # Return bdry(h) instead of h when norm is zero
    else:  # Return bdry(h) directly if it is all zeros
        return bdry(h)

def principal_diagonal(tensor: np.ndarray) -> np.ndarray:
    """
    Extracts the principal (simplicial) diagonal from a tensor given its dimension.
    Returns all elements (i, i, ..., i) for i in [0..dimen(tensor)].
    """
    sdim = dimen(tensor)
    # Generate indices (i, i, ..., i) for i in range(sdim + 1)
    indices = [tuple([i] * len(tensor.shape)) for i in range(sdim + 1)]
    return np.array([tensor[idx] for idx in indices])


def check_conjecture(shape: Tuple[int, ...], proceed_anyway: bool) -> bool:
    """
    Checks whether the given shape satisfies the n-hypergroupoid conjecture.
    If not, prints a warning and returns False unless proceed_anyway is True.
    """
    conjecture = n_hypergroupoid_conjecture(shape, verbose=True)
    if not conjecture:
        print(f"Shape does not satisfy the n-hypergroupoid conjecture: {shape}")
        if not proceed_anyway:
            return False
    return True


def check_nondegenerate_boundary(t: np.ndarray, proceed_anyway: bool, verbose: bool = False) -> bool:
    """
    Checks that the boundary of tensor t is non-degenerate.
    If degenerate and proceed_anyway is False, returns False.
    """
    b = bdry(t)
    if is_degen(b):
        print("Boundary of the tensor is degenerate.")
        if verbose:
            print("Boundary of the tensor:")
            print(b)
        if not proceed_anyway:
            return False
    return True


def check_horn(t: np.ndarray,
               shape: Tuple[int, ...],
               shape_face: np.ndarray,
               z: np.ndarray,
               i: int) -> bool:
    """
    Checks if the horn of dimension i in tensor t correctly identifies
    the missing face, and that the filler matches the original tensor.
    """
    h = horn(t, i)
    occurrence_tensor = np.zeros(shape, dtype=int)

    # Outer loop: iterate over each face in the horn
    for face_idx in range(len(h)):
        b = h[face_idx]
        # If b is not the zero face
        if not np.equal(b, z).all():
            # Inner loop: track occurrences of each element in b
            # Use a different variable name to avoid overshadowing face_idx
            num_face_elems = np.prod(shape_face)
            for elem_idx in range(num_face_elems):
                element = int(b[get_index(elem_idx, tuple(shape_face))])
                # Increment occurrence count for that element index in occurrence_tensor
                occurrence_tensor[get_index(element, shape)] += 1

    # Check if the principal diagonal's largest index matches i
    diag_argmax = principal_diagonal(occurrence_tensor).argmax()
    if i != diag_argmax:
        print(f"Counterexample with index disagreement: {shape}. Expected {i}, got {diag_argmax}.")
        return False

    # Compute the filler of the horn
    f = filler(h, i)
    if not np.array_equal(t, f):
        print(f"Counterexample: filler != original tensor for shape {shape}")
        return False

    return True


def reconstruct_range_tensor_from_horn(shape: Tuple[int, ...],
                                       proceed_anyway: bool = False,
                                       verbose: bool = False) -> bool:
    """
    Attempts to reconstruct a range tensor of given shape from its horns.
    If the n-hypergroupoid conjecture and non-degenerate boundary checks pass,
    it validates each dimension's horn.
    """
    t = range_tensor(shape)

    # 1. Check the n-hypergroupoid conjecture
    if not check_conjecture(shape, proceed_anyway):
        return False

    # 2. Check that the boundary is non-degenerate
    if not check_nondegenerate_boundary(t, proceed_anyway, verbose=verbose):
        return False

    # 3. Reconstruct from horns
    s = dimen(t)
    shape_face = np.subtract(shape, np.array([1]))
    z = np.zeros(shape_face)

    for i in range(1, s + 1):
        if not check_horn(t, shape, shape_face, z, i):
            return False

    # If all horns pass, the reconstruction is correct
    # Optionally print a success message:
    # print(f"Reconstruction successful for shape {shape}")
    return True

def bdry_mod1(w: np.ndarray) -> np.ndarray:
    """
    Computes the boundary of w and then reduces each entry modulo 1.
    Returns the result in [0,1), with 1.0 mapped to 0.0
    """
    bdry_w = bdry(w)
    result = bdry_w - np.floor(bdry_w)
    # Map any 1.0 values (which are actually 0 mod 1) to 0.0
    result[np.isclose(result, 1.0)] = 0.0
    return result

def random_real_matrix(shape: Tuple[int, ...], low=-10.0, high=10.0, seed: int = 123) -> np.ndarray:
    """
    Generates a real-valued matrix of given 'shape' with values 
    uniformly distributed in [low, high].
    """
    rng = np.random.default_rng(seed)
    return rng.uniform(low, high, size=shape)

def random_axis_permutation(k: int) -> Tuple[int, ...]:
    """
    Return a random permutation of the k axes.
    """
    return tuple(random.sample(range(k), k))

def permute_tensor(T: np.ndarray, perm: Tuple[int, ...]) -> np.ndarray:
    """
    Apply an axis permutation perm to tensor T.
    """
    return T.transpose(perm)


def cyclic(t: np.ndarray) -> np.ndarray:
    """
    Simplicial cycle on the *first* d+1 axes of t, where
      d = dimen(t) = min(t.shape)-1.
    Builds the explicit permutation
      σ = (1,2,...,d,0, d+1, d+2, ..., k-1)
    and applies it via permute_tensor.
    """
    from tensor_ops import permute_tensor, dimen

    d = dimen(t)
    k = t.ndim
    # the cycle on simplex‐axes 0..d:
    sigma: Tuple[int, ...] = tuple(
        list(range(1, d+1))  # 1→2→...→d
        + [0]                # d→0
        + list(range(d+1, k))  # leave the remaining axes alone
    )
    return permute_tensor(t, sigma)


def cyclic_signed(t: np.ndarray) -> np.ndarray:
    """
    Connes’ signed cycle λ = (-1)^d * τ,
    where τ = cyclic(t) on the first d+1 axes.
    """
    from tensor_ops import dimen

    d = dimen(t)
    sign = -1 if (d % 2) else 1
    return sign * cyclic(t)


if __name__ == "__main__":
    # more counterexamples from manvel and stockmeyer 1971
    __NONDEGENERATE_BASE__ = "Non-degenerate base matrix:"
    __DEGENERACY_OPERATIONS__ = "Sequence of degeneracy operations:"

    def matrix_m(n: int) -> np.ndarray:
        j = int(np.ceil(n // 2))
        A = np.zeros((n,n))
        A[0,j] = 1
        A[j,0] = 1
        return A

    def matrix_n(n: int) -> np.ndarray:
        A = np.zeros((n,n))
        j = int(np.ceil(n // 2))+1
        A[0,j] = 1
        A[j,0] = 1
        return A
    
    m = matrix_m(5)
    print("M:", m)
    print("is_degen(M):", is_degen(m))
    non_degen_base, ops = decompose_degen(m)
    print(__NONDEGENERATE_BASE__, non_degen_base)
    print(__DEGENERACY_OPERATIONS__, ops)

    n = degen(degen(degen(matrix_n(3),2),3),4)
    print("n:", n)
    print("is_degen(n):", is_degen(n))
    non_degenerate_base, ops = decompose_degen(n)
    print(__NONDEGENERATE_BASE__, non_degenerate_base)
    print(__DEGENERACY_OPERATIONS__, ops)

    X = np.array([[0, 0, 1, 0],
                [0, 0, 0, 0],
                [1, 0, 0, 0,],
                [0, 0, 0, 0]])
    print("X:", X)
    print("is_degen(X):", is_degen(X))
    non_degenerate_base, ops = decompose_degen(X)
    print(__NONDEGENERATE_BASE__, non_degenerate_base)
    print(__DEGENERACY_OPERATIONS__, ops)

    Y = np.array([[0, 0, 0, 0],
                [0, 0, 0, 0],
                [0, 0, 0, 0,],
                [0, 0, 0, 0]])
    print("Y:", Y)
    print("is_degen(Y):", is_degen(Y))
    non_degenerate_base, ops = decompose_degen(Y)
    print(__NONDEGENERATE_BASE__, non_degenerate_base)
    print(__DEGENERACY_OPERATIONS__, ops)

    
    
    shape = (7, 9, 11, 12)
    can_reconstruct = reconstruct_range_tensor_from_horn(shape, proceed_anyway=True)
    print(f"Range tensor of shape {shape} can be reconstructed from any horn: {can_reconstruct}") 
    

    w = random_real_matrix((7, 9), low=-10, high=10, seed=123)
    print("w:", w)
    print("bdry(w):", bdry(w))
    print("bdry_mod1(w):", bdry_mod1(w))
    print("bdry_mod1(bdry_mod1(w)):", bdry_mod1(bdry_mod1(w)))
